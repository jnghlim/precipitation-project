{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit ('base': conda)"
  },
  "interpreter": {
   "hash": "73b6ae8506bdc19ed589a00e1d262f774847aba16200b38cb2aa76144baf0813"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "source": [
    "Save all the csv files for each year in dictionary."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "19"
      ]
     },
     "metadata": {},
     "execution_count": 177
    }
   ],
   "source": [
    "data_holder = {}\n",
    "min_year = 2002\n",
    "max_year = 2020\n",
    "\n",
    "for year in range(min_year, max_year+1):\n",
    "    data_holder['data_'+str(year)] = pd.read_csv(f'weather_of_{year}.csv')\n",
    "\n",
    "len(data_holder)"
   ]
  },
  {
   "source": [
    "Shows all the NA values for each csv file."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'data_2002': 18,\n",
       " 'data_2003': 20,\n",
       " 'data_2004': 17,\n",
       " 'data_2005': 9,\n",
       " 'data_2006': 17,\n",
       " 'data_2007': 7,\n",
       " 'data_2008': 15,\n",
       " 'data_2009': 15,\n",
       " 'data_2010': 9,\n",
       " 'data_2011': 16,\n",
       " 'data_2012': 17,\n",
       " 'data_2013': 16,\n",
       " 'data_2014': 6,\n",
       " 'data_2015': 7,\n",
       " 'data_2016': 11,\n",
       " 'data_2017': 3,\n",
       " 'data_2018': 10,\n",
       " 'data_2019': 8,\n",
       " 'data_2020': 13}"
      ]
     },
     "metadata": {},
     "execution_count": 178
    }
   ],
   "source": [
    "na_values_holder = {}\n",
    "\n",
    "for x,y in zip(data_holder.keys(),data_holder.values()):\n",
    "    na_values_holder[x] = y.isna().any(axis=1).sum()\n",
    "\n",
    "na_values_holder\n"
   ]
  },
  {
   "source": [
    "Tried to fill NA values which are in 'Pct Avg to Date', but I could not figure out how to calculate for this column and it turns out that there are only few rows that are missing this column so I decided to drop these rows that consist NA values in 'Pct Avg to Date' column"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for x in data_holder.values():\n",
    "    x.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'data_2002': 0,\n",
       " 'data_2003': 0,\n",
       " 'data_2004': 0,\n",
       " 'data_2005': 0,\n",
       " 'data_2006': 0,\n",
       " 'data_2007': 0,\n",
       " 'data_2008': 0,\n",
       " 'data_2009': 0,\n",
       " 'data_2010': 0,\n",
       " 'data_2011': 0,\n",
       " 'data_2012': 0,\n",
       " 'data_2013': 0,\n",
       " 'data_2014': 0,\n",
       " 'data_2015': 0,\n",
       " 'data_2016': 0,\n",
       " 'data_2017': 0,\n",
       " 'data_2018': 0,\n",
       " 'data_2019': 0,\n",
       " 'data_2020': 0}"
      ]
     },
     "metadata": {},
     "execution_count": 182
    }
   ],
   "source": [
    "na_values_holder = {}\n",
    "\n",
    "for x,y in zip(data_holder.keys(),data_holder.values()):\n",
    "    na_values_holder[x] = y.isna().any(axis=1).sum()\n",
    "\n",
    "na_values_holder"
   ]
  }
 ]
}